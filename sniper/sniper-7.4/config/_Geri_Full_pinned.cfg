[general]
total_cores = 4

[progress_trace]
enable = true
interval = 5000
filename = "progress_trace"

[clock_skew_minimization]
scheme = barrier
report = false

[clock_skew_minimization/barrier]
quantum = 100

# This section describes parameters for the core core_model
[perf_model/core]
logical_cpus = 1  # number of SMT threads per core
frequency[] = 2.8,1.6,1.6,1.6
het_type[] = 2,0,0,0                       
type = interval
core_model = nehalem

[perf_model/core/iocoom]
num_store_buffer_entries = 20  # store queue
num_outstanding_loadstores = 32  # load queue

[perf_model/branch_predictor]
mispredict_penalty[] = 14,10,10,10

[perf_model/core/interval_timer]
dispatch_width = 2
issue_contention = "true" 
lll_cutoff = 30
memory_dependency_granularity = 4
num_outstanding_loadstores = 8
window_size = 64
dispatch_width[] = 4,2,2,2
window_size[] = 256,64,64,64 #ROB size

[perf_model/cache]
levels = 3

[perf_model/tlb]
penalty = 30          # Page walk penalty in cycles

[perf_model/itlb]
size = 128            # Number of I-TLB entries
associativity = 4     # I-TLB associativity

[perf_model/dtlb]
size = 64             # Number of D-TLB entries
associativity = 4     # D-TLB associativity

[perf_model/stlb]
size = 512            # Number of second-level TLB entries
associativity = 4     # S-TLB associativity

[perf_model/l1_icache]
perfect = false
coherent = true
cache_size[] = 16,16,16,16 #KB
associativity = 4
address_hash = mask
replacement_policy = lru
data_access_time = 4
tags_access_time = 1
perf_model_type = parallel
writeback_time = 0
writethrough = 0
dvfs_domain = core
shared_cores = 1
cache_block_size = 64 #IVAN

[perf_model/l1_dcache]
perfect = false
cache_size[] = 16,16,16,16
associativity = 8
address_hash = mask
replacement_policy = lru
data_access_time = 4
tags_access_time = 1
perf_model_type = parallel
writeback_time = 0
writethrough = 0
shared_cores = 1
cache_block_size = 64 #IVAN

[perf_model/l2_cache]
perfect = false
cache_size[] = 256,128,128,128
associativity = 8
address_hash = mask
replacement_policy = lru
data_access_time = 8
tags_access_time = 3
# Total neighbor L1/L2 access time is around 40/70 cycles (60-70 when it is coming out of L1)
dvfs_domain = core
writeback_time = 50
perf_model_type = parallel
writethrough = 0
prefetcher = none
shared_cores = 1
cache_block_size = 64 #IVAN

[perf_model/l3_cache]
perfect = false
cache_size = 8192
associativity = 16
replacement_policy = lru
address_hash = mask
data_access_time = 30
tags_access_time = 10
writeback_time = 30
dvfs_domain = global
perf_model_type = parallel
writethrough = 0
shared_cores = 4
prefetcher = none
cache_block_size = 64 #IVAN

#[caching_protocol]
type = parametric_dram_directory_msi
variant = mesi

[perf_model/dram_directory]
# total_entries - number of entries per directory controller
total_entries = 1048576
associativity = 16
directory_type = full_map

[perf_model/dram]
# -1 means that we have a number of distributed DRAM controllers
num_controllers = -1
#type = constant
controllers_interleaving = 4                      
# DRAM access latency in nanoseconds. Should not include L1-LLC tag access time, directory access times
# Membench says 175 cycles @ 2.66 Ghz = 66ns total
latency = 45
per_controller_bandwidth = 7.6
chips_per_dimm = 8
dimms_per_controller = 4

[scheduler]
type = pinned

[scheduler/pinned]
quantum = 1000000

[traceinput]
stop_with_first_thread = true

[network]
memory_model_1 = bus
memory_model_2 = bus

[network/bus]
bandwidth = 25.6   # in GB/s. Actually, it's 12.8 GB/s per direction and per connected chip pair
ignore_local_traffic = true

#[power]
vdd = 1.2 # Volts
technology_node = 45 # nm
