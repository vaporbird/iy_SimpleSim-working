[general]
total_cores = 8

[progress_trace]
enable = true
interval = 5000
filename = "progress_trace"

[clock_skew_minimization]
scheme = barrier
report = false

[clock_skew_minimization/barrier]
quantum = 100

# This section describes parameters for the core core_model
[perf_model/core]
frequency = 2.66
frequency[] = 2.66,2.66,2.66,2.66,2.66,2.66,2.66,2.66
het_type[] = 2,2,2,2,2,2,2,2
type = interval
core_model = nehalem
logical_cpus = 4  # number of SMT threads per core

[perf_model/core/iocoom]
num_store_buffer_entries = 48  # store queue
num_outstanding_loadstores = 48  # load queue

[perf_model/branch_predictor]
mispredict_penalty = 8
mispredict_penalty[] = 8,14,14,14,8,14,14,14   # A guess based on Penryn pipeline depth
size = 1024

[perf_model/core/interval_timer]
dispatch_width = 4
window_size = 128
dispatch_width[] = 8,4,4,4,8,4,4,4
window_size[] = 128,16,16,16,128,16,16,16    #ROB size
num_outstanding_loadstores = 48
memory_dependency_granularity = 8

[perf_model/cache]
levels = 3

[perf_model/l1_icache]
perfect = false
coherent = true
cache_size[] = 64,64,64,64,64,64,64,64 #KB
associativity = 8
address_hash = mask
replacement_policy = lru
data_access_time = 4
tags_access_time = 1
perf_model_type = parallel
writeback_time = 0
writethrough = 1
dvfs_domain = core
shared_cores = 1
cache_block_size = 64 #IVAN

[perf_model/l1_dcache]
perfect = false
cache_size[] = 64,64,64,64,64,64,64,64
associativity = 8
address_hash = mask
replacement_policy = lru
data_access_time = 4
tags_access_time = 1
perf_model_type = parallel
writeback_time = 0
writethrough = 1
shared_cores = 1
cache_block_size = 64 #IVAN

[perf_model/l2_cache]
perfect = false
cache_size[] = 256,256,256,256,256,256,256,256
associativity = 8
address_hash = mask
replacement_policy = lru
data_access_time = 8
tags_access_time = 3
# Total neighbor L1/L2 access time is around 40/70 cycles (60-70 when it is coming out of L1)
#dvfs_domain = core
perf_model_type = parallel
writeback_time = 50
writethrough = 0
prefetcher = none
shared_cores = 1
cache_block_size = 64 #IVAN

[perf_model/l3_cache]
perfect = false
cache_size = 8192
associativity = 16
address_hash = mask
replacement_policy = lru
data_access_time = 30
tags_access_time = 10
writeback_time = 30
dvfs_domain = global
perf_model_type = parallel
writethrough = 0
shared_cores = 8
prefetcher = none
cache_block_size = 64 #IVAN


[caching_protocol]
type = parametric_dram_directory_msi
variant = mesi

[perf_model/dram_directory]
# total_entries - number of entries per directory controller
total_entries = 1048576
associativity = 16
directory_type = full_map

[perf_model/dram]
# -1 means that we have a number of distributed DRAM controllers
num_controllers = -1
#type = constant
controllers_interleaving = 4
# DRAM access latency in nanoseconds. Should not include L1-LLC tag access time, directory access times
# Membench says 175 cycles @ 2.66 Ghz = 66ns total
latency = 60
per_controller_bandwidth = 7.6
chips_per_dimm = 8
dimms_per_controller = 4

[scheduler]
type = big_small

[scheduler/big_small]
quantum = 1000000

[network]
memory_model_1 = bus
memory_model_2 = bus

[network/bus]
bandwidth = 25.6   # in GB/s. Actually, it's 12.8 GB/s per direction and per connected chip pair
ignore_local_traffic = true

[power]
vdd = 1.2 # Volts
technology_node = 45 # nm
